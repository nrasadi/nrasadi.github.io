---
title: "Variant Generation and Diversity Strategies for Enhanced Variant Parallelism in Edge AI"
tags: "Edge Computing, Deep Learning, Distributed Systems, Distributed Deep Learning, Efficient Deep Learning, Scalable Deep Learning, Ensemble Learning, Model Diversity, Model Compression"
authors: "Navidreza Asadi, Sagnik Dutta, Wolfgang Kellerer"
type: "c"
place: "IEEE Globecom 2025 Workshop on A4E: AI/ML for Edge/Fog Networks"
date: "2025/12/08"
status: "a"
# award: "Best Poster Award"
pdf: files\papers\NavidrezaAsadi_GlobeCom2025-A4E_VIP.pdf
# link: "https://doi.org/10.1145/3737899.3768527"
link: "https://globecom2025.ieee-globecom.org/workshop/ws-17-third-workshop-a4e-aiml-edgefog-networks/program"
bibtex: "
@inproceedings{asadi2025vip,
  title={Variant Generation and Diversity Strategies for Enhanced Variant Parallelism in Edge AI},
  author={Asadi, Navidreza and Dutta, Sagnik and Kellerer, Wolfgang},
  booktitle={{IEEE Globecom 2025 Workshop on A4E: AI/ML for Edge/Fog Networks}},
  year={2025}
}
"
---
Serving deep learning models on IoT edge devices faces considerable challenges because of their restricted computational capabilities. Variant Parallelism (VP) mitigates this by distributing lightweight model variants, but has two main limitations: (i) variant generation typically lacks a systematic approach to ensure diversity, and (ii) ensembles composed of identical-sized variants underperform compared to heterogeneous ensembles. To address these issues, we propose Variant-Improved Parallelism (VIP), which advances VP through two main innovations. First, VIP introduces a structured variant generation pipeline that leverages knowledge distillation and targeted model slicing to efficiently produce diverse variants. Second, it employs diversity-inducing methods, such as data augmentation and class-imbalanced training, to enable effective homogeneous ensembles, expanding VP’s utility in environments with similar device capabilities. Experiments on ResNet50 with CIFAR10, CIFAR100, and ImageNet-1K demonstrate that VIP achieves consistent accuracy gains of up to 10%, while preserving VP’s advantages in fault tolerance and communication efficiency, supporting scalable and adaptive edge AI deployments.
